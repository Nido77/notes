{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["![](https://cdn.jsdelivr.net/gh/Nido77/notesimage@main/img/202212131458727.png)"]},{"cell_type":"markdown","metadata":{},"source":["# 1. tensor overview\n","\n","一种特殊的数据结构, 和array & matrix很像\n","\n","主要用途是:\n","1. encode model的输入输出\n","2. 存储model的parameters\n","\n","和numpy的ndarray区别是tensor可以使用GPU或者特制硬件来加速计算,而ndarray只能使用CPU进行计算"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# import\n","import torch\n","import numpy as np"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Tensor的初始化\n","\n","1. 直接从数据中初始化\n","2. 从numpy array中初始化\n","3. 从另一个tensor中初始化\n","4. 使用随机数/常数进行初始化\n"]},{"cell_type":"markdown","metadata":{},"source":["## 2.1 直接从数据中初始化\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2],\n","        [3, 4]])\n"]}],"source":["data = [[1, 2], [3, 4]]\n","x_data = torch.tensor(data)\n","\n","print(x_data)"]},{"cell_type":"markdown","metadata":{},"source":["## 2.2 从numpy array中初始化\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2],\n","        [3, 4]])\n"]}],"source":["np_array = np.array(data)               \n","x_np = torch.from_numpy(np_array)\n","print(x_np)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2.3 从其他tensor中初始化"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ones Tensor: \n"," tensor([[1, 1],\n","        [1, 1]]) \n","\n","Random Tensor: \n"," tensor([[0.1730, 0.3374],\n","        [0.2188, 0.3984]]) \n","\n"]}],"source":["x_ones = torch.ones_like(x_data)                    # same dimension with x_data with all value = 1\n","print(f\"Ones Tensor: \\n {x_ones} \\n\")\n","\n","x_rand = torch.rand_like(x_data, dtype=torch.float) # same dimension with x_data with all value are random\n","print(f\"Random Tensor: \\n {x_rand} \\n\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 2.4 使用随机数/常数进行初始化"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Tensor: \n"," tensor([[0.2176, 0.7593, 0.9799],\n","        [0.7016, 0.8257, 0.6672]]) \n","\n","Ones Tensor: \n"," tensor([[1., 1., 1.],\n","        [1., 1., 1.]]) \n","\n","Zeros Tensor: \n"," tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"]}],"source":["shape = (2, 3,)                     # determine the dimension of tensors\n","rand_tensor = torch.rand(shape)     # random value with dimension = shape\n","ones_tensor = torch.ones(shape)\n","zeros_tensor = torch.zeros(shape)\n","\n","print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n","print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n","print(f\"Zeros Tensor: \\n {zeros_tensor}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 3. Tensor的属性\n","主要包括shape,datatype,存储在哪个设备上"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of tensor: torch.Size([3, 4])\n","Datatype of tensor: torch.float32\n","Device tensor is stored on: cpu\n"]}],"source":["tensor = torch.rand(3, 4)\n","\n","print(f\"Shape of tensor: {tensor.shape}\")\n","print(f\"Datatype of tensor: {tensor.dtype}\")\n","print(f\"Device tensor is stored on: {tensor.device}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 4. Tensor操作\n","这里只介绍以下几种操作,如有需求可以看[这里](https://pytorch.org/docs/stable/torch.html)\n","1. 从CPU移动到GPU\n","2. index & slice\n","3. 合并\n","4. tensor乘法\n","5. tensor的in-place操作"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4.1 tensor移动到GPU\n","\n","mac端没有cuda,所以将就看一下"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# We move our tensor to the GPU if available\n","if torch.cuda.is_available():\n","  tensor = tensor.to('cuda')\n","  print(f\"Device tensor is stored on: {tensor.device}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4.2 index & slice"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.],\n","        [1., 0., 1., 1.]])\n"]}],"source":["tensor = torch.ones(4, 4)\n","tensor[:,1] = 0                     # 将 2nd dimension set = 0 \n","print(tensor)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4.3 tensor合并\n","\n","使用`torch.cat`"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[[1., 1., 1., 1.],\n","         [2., 2., 2., 2.],\n","         [2., 2., 2., 2.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.]],\n","\n","        [[1., 1., 1., 1.],\n","         [2., 2., 2., 2.],\n","         [2., 2., 2., 2.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.]],\n","\n","        [[1., 1., 1., 1.],\n","         [2., 2., 2., 2.],\n","         [2., 2., 2., 2.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.]],\n","\n","        [[1., 1., 1., 1.],\n","         [2., 2., 2., 2.],\n","         [2., 2., 2., 2.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.],\n","         [3., 3., 3., 3.]]])\n"]}],"source":["t1 = torch.ones(4, 1, 4)\n","t2 = 2*torch.ones(4, 2, 4)\n","t3 = 3*torch.ones(4, 3, 4)\n","t1 = torch.cat([t1, t2, t3], dim=1)     # 除了合并的维度,其他都应该一样\n","print(t1)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4.4 tensor乘法"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor.mul(tensor) \n"," tensor([[9., 9.],\n","        [9., 9.]]) \n","\n","tensor * tensor \n"," tensor([[9., 9.],\n","        [9., 9.]])\n"]}],"source":["# 这个是Hadamard product\n","tensor = 3*torch.ones(2, 2)\n","print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n","# 另一种写法:\n","print(f\"tensor * tensor \\n {tensor * tensor}\")\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor.matmul(tensor.T) \n"," tensor([[8.]]) \n","\n","tensor @ tensor.T \n"," tensor([[8.]])\n"]}],"source":["# 矩阵乘法\n","tensor = 2*torch.ones(1, 2)\n","\n","print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n","# Alternative syntax:\n","print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4.5 in-place Operations\n","在函数名后面加一个_会直接在该变量的内存上操作"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["before transpose x:tensor([[1., 1.]])\n","after transpose x:tensor([[1.],\n","        [1.]])\n"]}],"source":["x = torch.ones(1, 2)\n","print(f\"before transpose x:{x}\")\n","x.t_()\n","print(f\"after transpose x:{x}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 5. 和NumPy的互相转换\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 5.1 Tensor to Numpy array\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([1., 1., 1., 1., 1.])\n","n: [1. 1. 1. 1. 1.]\n","t: tensor([2., 2., 2., 2., 2.])\n","n: [2. 2. 2. 2. 2.]\n"]}],"source":["t = torch.ones(5)\n","print(f\"t: {t}\")\n","n = t.numpy()\n","print(f\"n: {n}\")\n","\n","# 这两个指针指向的是同一个内存空间, 但是前提是tensor存在CPU而非GPU上\n","t.add_(1)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 5.2 NumPy array to Tensor"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["t: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n","n: [1. 1. 1. 1. 1.]\n"]}],"source":["n = np.ones(5)\n","t = torch.from_numpy(n)\n","print(f\"t: {t}\")\n","print(f\"n: {n}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.15 ('pytorch')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ffe3962f9b8453bbeea4429287d0b4ad8aa51431f35102b7a0c46ad35d769714"}}},"nbformat":4,"nbformat_minor":2}
